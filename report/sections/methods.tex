\chapter*{2. Methods}
\markboth{Methods}{}
\setcounter{chapter}{2}
\setcounter{section}{0}
\addcontentsline{toc}{chapter}{2. Methods}

The preceding chapter summarised a review of the literature relating to twins, correlations, power and simulations undertaken to inform our approach to analysis.  Through this review we identified a series of suitable approaches and tests for evaluating differences in Pearson and Spearman correlations in two groups. Important considerations were the efficiency of our implemented simulation functions, and a well-designed data structure to support our planned as well as future outputs.  The $R$ programming environment was used for all analyses \cite{R2018}.

\section{Hypothesis tests for difference in correlations}
\subsection{Fisher's Z test (analytical approach)}
A test statistic for the difference in correlations can be calculated as the difference in Fisher's Z transformed values weighted by the approximate standard error of the difference \cite{Fisher1990,David1938}
$$t_{\hat{\theta}} = {\frac{\hat{\theta}}{se_\hat{\theta}}} = {\frac{z_{MZ} - z_{DZ}}{\sqrt{(n_{MZ}-3)^{-1}+(n_{DZ}-3)^{-1}}}} $$

The type 2 error rate $\beta$ is estimated through comparison of this test statistic $t_{\hat{\theta}}$ to a reference value on the standard normal distribution.   Using the cumulative normal distribution function $\Phi$ (Phi), the reference score $q$ is calculated as the normal probability quantile corresponding to our $\alpha$ level divided by the sidedness of our test. 
 $$q = \Phi^{-1}(\alpha/\text{sidedness})$$
Where we refer to sidedness, we mean whether we are concerned with a single- or two-tailed probability.  Here, we are testing the hypothesis that $\rho_{MZ} = \rho_{DZ}$ using a two-tailed p-value, implying 'admissible alternatives' to be the case that $\rho_{MZ}$ is greater than or less than $\rho_{DZ}$, that is, $|\rho_{MZ} - \rho_{DZ}| > 0$ \cite{David1938}.  One-tailed consideration, for example that $\rho_{MZ} > \rho_{DZ}$, is not considered in this report however, the functions developed may be parameterised in this way if desired. 
\\
Employing the concepts detailed above, $\beta$ is calculated as 
$$\beta = \Phi \big( q - t_\theta \big)$$
Our power estimate for the detection of difference in correlations is $\power(\theta) = 1 - \beta$. Putting the above altogether, we calculate power using the Fisher's $z$ test statistic as,

$$ \power = 1- \Phi \Bigg(\Phi_{\alpha/2}^{-1} -  \abs\bigg(  \frac{\arctanh(r_{MZ}) - \arctanh(r_{DZ})}{\sqrt{(n_{MZ}-3)^{-1} + (n_{DZ}-3)^{-1}}}  \bigg)  \Bigg) $$ 

The code we used to implement the analytic Fisher's Z test approach to power calculation in $R$ is displayed in listing \ref{lst:fz_nosim}.

\begin{lstlisting}[float=h,caption={Fisher's Z test (analytic approach)},label={lst:fz_nosim}]
# Fishers Z test - no sim
fz_nosim <- function(r1,r2,n1,n2,
                     alpha = 0.05, sidedness=2,method = "pearson",
                     power = TRUE) {
  # Calculate Fisher's Z
  z1     <- atanh(r1)
  z2     <- atanh(r2)
  
  # Take difference
  zdiff  <- z1-z2
  
  # Calculate standard error and test statistic
  z_se   <- sqrt(1/(n1-3) + 1/(n2-3))
  z_test <- zdiff/z_se
  
  # Optionally return p-value for observing diff at least this large under H0
  z_p    <- sidedness*pnorm(-abs(z_test))
  if (power == FALSE) return("p" = z_p)
  z_ref   <- qnorm(1-alpha/sidedness)
  z_power <- 1-pnorm(z_ref - abs(z_test))
  return(z_power)
}
\end{lstlisting}

The above method is the de facto standard, as used for example in the Stata \code{power two correlations} \cite{StataCorp2013}.  However, other options for evaluating the difference in Pearson or Spearman correlations should be considered.  

\subsection{Fisher's Z test (simulation approach)}
Using a simulation approach we take our hypothesis tests and apply them to draws from simulated data designed to mimic our samples through parameterisation using the hypothesised underlying bivariate population distributions.  
\\
\\
So where in our formula we might plug in hypothesised sample coefficients of 0.2 and 0.5, in the simulation we use these values to represent the true correlations in the underlying population from which we draw our samples.  Over a large number of simulations of bivariate twin data the proportion of hypothesis tests returning p-values lower than our type 1 error threshold is our power estimate.
\\
\\
The simulation-based Fisher's Z test function $R$ code is displayed in listing \ref{lst:fz}.

\begin{lstlisting}[float=h,caption={Fisher's Z test (simulation approach)},label={lst:fz}]
# Fishers Z test
fz <- function(a,b,sidedness=2,method = "pearson") {
  # Two samples
  n1 <- nrow(a)
  n2 <- nrow(b)
   
  # Compute z-transformed sample correlation coefficients
  z1     <- atanh(cor(a,method = method)[2,1])
  z2     <- atanh(cor(b,method = method)[2,1])
  zdiff  <- z1-z2
  
  # calculate standard error and test statistic
  z_se   <- sqrt(1/(n1-3) + 1/(n2-3))
  z_test <- zdiff/z_se
  
  # return p-value
  z_p    <- sidedness*pnorm(-abs(z_test))
  return(z_p)
}
\end{lstlisting}


In addition to applying the Fisher Z test in a simulation context, alternate tests we identified and implemented for inclusion in our simulation study were as follows. 

\subsection{Zou's confidence interval}
Zou's confidence interval is used to calculate a confidence interval for the difference in two correlations, and a hypothesis test employing this method is featured in the R package \code{cocor} \cite{Zou2007,Diedenhofen2015}.  A hypothesis test using Zou's confidence interval evaluates whether zero lies within the lower and upper bounds of the interval estimate of the difference in correlations, returning 1 if so or otherwise zero.  Over a run of simulations this would be expected to return identical results to the Fisher Z test, but may be more efficient.
\\
\\
Zou's approach expands on earlier work \cite{Olkin1995} to calculate a confidence interval for a difference in correlations using a so-called Simple Asymptotic approach, using what Zou refers to as a Modified Asymptotic method \cite{Zou2007}.  Both approaches draw heavily on Fisher's earlier work \cite{Fisher1990}.  The modified asymptotic method of Zou consists of first calculating confidence intervals for the two respective z-transformed correlations (transformed as per Fisher's method, described above):
$$(l_{z_k}, u_{z_k}) = z_k \pm \sqrt{\frac{1}{n_k - 3}} \times \Phi_{\alpha/2}^{-1},\ \text{where} \ k \in \{1,2\}$$

Then, the lower (L) and upper (U) bounds of the modified asymptotic confidence interval for the difference in correlations are calculated:
$$L = r_1 - r_2 - \sqrt{(r_1 - \tanh(l_{z_1}))^2 + (\tanh(u_{z_2})- r_2)^2}$$
$$U = r_1 - r_2 + \sqrt{(\tanh(u_{z_1}) - r_1)^2 + (r_2 - \tanh(l_{z_2}))^2}$$

If zero is within the bounds of the confidence interval for the difference, the test returns as 1, and otherwise 0.
\\
\\
Our implemenation of the Zou's confidence interval test function is displayed in listing \ref{lst:zou}.

\begin{lstlisting}[float=h,caption={Zou's confidence interval},label={lst:zou}]
zou <- function(a,b,alpha = 0.05,sidedness=2,method = "pearson") {
  # From Zou (2007) and used in Cocor (note typo for U in paper; should be '+')
  #  However, really, this is equivalent to fz test for hypothesis testing purposes
  
  # compute z- transformed correlations and differences
  r  <- c(cor(a,method = method)[2,1], cor(b,method = method)[2,1])
  z  <- atanh(r)
  zdiff  <- z[1]-z[2]
  
  # calculate standard error for respective z scores
  n  <- c(nrow(a),nrow(b))
  z_se   <- sqrt(1/(n-3))

  # calculate reference threshold
  z_ref  <- qnorm(1-alpha/sidedness)
  
  # calculate respective confidence intervals
  ci_mat <- matrix(c(-1,-1,1,1),nrow = 2, ncol = 2, dimnames =list(c("Mz","Dz"),c("l","u")))
  z_ci   <- z + ci_mat * z_se * z_ref
  r_ci   <- tanh(z_ci)
  
  # calculate Zou's Modified Asymptoptic confidence interval for difference in correlations
  L      <- r[1]-r[2] - sqrt((r[1]      - r_ci[1,1])^2 + (r_ci[2,2] - r[2]     )^2)
  U      <- r[1]-r[2] + sqrt((r_ci[1,2] - r[1]     )^2 + (r[2]      - r_ci[2,1])^2)
  r_diff_ci <- c(L,U)
  
  # return test value (0 or 1, however, in the power context this resolves to same outcome as p)
  ci_test <- (L < 0) && (0 < U)
  return(c(ci_test,r_diff_ci))
}
\end{lstlisting}



\subsection{Generalised Variable Test}

The generalised variable (GV) test involves transformation of the simulated sample correlations into so-called pivotal quantities the difference of which is used to calculate a test statistic and p-value \cite{Krishnamoorthy2014}. Synthesising two reported approaches \cite{Krishnamoorthy2007,Kazemi2016} this test was first implemented as an example by my supervisor Enes Makalic in a Matlab script, and subsequently adapted by myself as a function in R.  A compiled version using RCPP to leverage C++ routines for random number draws was suggested by my colleague Koen Simons, and adopted to improve the function's run time. However, this later version was not compatible with the parallelised simulation approach, and in this context the non-RCCP 'GVT-r' version was used.
\\
\\
Given two bivariate normal samples $k\in\{1,2\}$, the sample correlation coefficients $r_k$ are used to estimate two respective quantities $r_k^* = \frac{r_k}{\sqrt(1-r_k^2)}$, and the generalised variables $G_{\rho_k}$:
$$G_{\rho_k} = \frac{r_k^*\sqrt{W_k} - U_k}{\sqrt{(r_k^*\sqrt(W_k) - U_k)^2 + V_k}}$$
where,
$$U_k \sim N(0,1) ,\ V_k \sim \chi_{n_k - 1}^2 ,\ \text{and} \ W_k \sim \chi_{n_k-2}^2$$
A p-value using the GV test is calculated as twice the value of the smaller of two quantities: the proportion of differences in $G_{\rho_k}$ less than 0, and the proportion greater than 0.

The GV test function $R$ code is displayed in listing \ref{lst:gvtr}.

\begin{lstlisting}[float=h,caption={GV test (R version)},label={lst:gvtr}]
gvt_r <- function(a,b,M=1e4,method = "pearson") {
  # Two samples
  n1 <- nrow(a)
  n2 <- nrow(b)
  
  # Compute sample correlation coefficients
  r1 <- cor(a,method = method)[2,1]
  r2 <- cor(b,method = method)[2,1]
  r  <- c(r1,r2)
  
  # Generate random numbers
  V2     <- matrix(data=0, nrow = M, ncol = 2)
  V2[,1] <- rchisq(M, df = n1-1, ncp = 1)
  V2[,2] <- rchisq(M, df = n2-1, ncp = 1)
  
  W2     <- matrix(data=0, nrow = M, ncol = 2)
  W2[,1] <- rchisq(M, df = n1-2, ncp = 1)
  W2[,2] <- rchisq(M, df = n2-2, ncp = 1)
  
  Z <-matrix(data = rnorm(2*M), nrow=M, ncol = 2)
  
  # Compute test statistic
  rstar <- r/sqrt(1-r^2)
  top   <- c(sqrt(W2[,1])*rstar[1],sqrt(W2[,2])*rstar[2]) - Z
  G     <- top / sqrt( top^2 + V2 )
  
  # Compute p value
  Grho <- G[,1] - G[,2];
  p    <- 2*min( mean(Grho<0), mean(Grho>0) ); 
  return(p)
}
\end{lstlisting}

\subsection{Signed log-likelihood ratio test}
The signed log likelihood ratio (SLR) test is formulated as the signed difference in sample correlation coefficients multiplied by the square root of the sum of respective coefficients' log-likelihoods.  The test here is a partial implementation of a recently reported modified signed log-likelihood ratio (MSLR) test  for differences in two bivariate normal correlations \cite{Kazemi2016}. The SLR and MSLR tests are well established general hypothesis tests \cite{Barndorff1986,Barndorff1991,Diciccio2001,Krishnamoorthy2014}, the novelty in Kazemi and Jafari's approach being the applied context of difference in correlations. However, we (myself, nor my supervisors) were unable to successfully replicate the 'modified' portion of Kazemi and Jafari's reported algorithm.  Due to time constraints, and noting that the 'unmodified' SLR test appeared to return p-values similar to the other hypothesis tests it was decided that inclusion of the SLR test would be a valid option to consider.
\\
\\
The SLR test function $R$ code is displayed in listing \ref{lst:slr}.

\begin{lstlisting}[float=h,caption={Signed log-likelihood ratio test},label={lst:slr}]
slr <- function(a,b,M=1e4,sidedness=2,method = "pearson") {
  # Signed Log-likelihood Ratio test (an 'unmodified' version of test 
  # described in Krishnamoorthy and Lee, Kazemi and Jafari , DiCiccio etc)
  # Two samples
  n  <- c(nrow(a),nrow(b))
  
  # Compute z-transformed sample correlation coefficients
  r  <- c(cor(a,method = method)[2,1], cor(b,method = method)[2,1])
  z  <- atanh(r)
  
  # Calculate average z as a plug in value
  rf <- tanh(mean(z))
  
  # calcaulte SLR
  slr <-sign(r[1]-r[2])*sqrt(sum(n*log(((1-rf*r)^2)/((1-r^2)*(1-rf^2)))))
  
  # return p-value
  p    <- 2 * (1 - pnorm(abs(slr))); 
  return(p)
}
\end{lstlisting}

\subsection{Permutation test}
The permutation test is a non-parametric approach which compares the absolute 
difference of the Z-transformed sample correlations with those using correlations 
from a series of group membership permutations using the sample rank orders as 
values.  Under a hypothesis of no difference in correlation, those differences arising from permutations would be assumed to be equally likely as those observed, or anticipated to be observed \cite{Efron1993}.  Across a series of $M$ permutations (in this study, 10,000), a $p$-value is calculated as the proportion of permutation derived absolute differences (($\abs(z_{MZ}^* - z_{DZ}^*)$)) of greater magnitude than $\abs(z_{MZ} - z_{DZ})$.
\\
\\
The implementation of this permutation test in $R$ is displayed in listing \ref{lst:pt}.

\begin{lstlisting}[float=h,caption={Permutation test},label={lst:pt}]
pt <- function(a,b,M=1e4,sidedness=2,method = "pearson") {
  # Based on Efron and Tibshirani, 1993
  # Store size, and calculate z-transformed correlations
  n  <- c(nrow(a),nrow(b))
  r  <- c(cor(a,method = method)[2,1], cor(b,method = method)[2,1])
  z  <- atanh(r)
  
  # Store rank-ordered vector representations, in one column
  v  <- cbind(rank(rbind(a[,1],b[,1]),ties.method = "random"),
              rank(rbind(a[,2],b[,2]),ties.method = "random"))
  # label rows
  rownames(v) <- c(rep("A",n[1]),rep("B",n[2]))
  
  # initial empty test vector
  rtest <- numeric(0)
  
  # run M permutations (default is 10,000),
  #  - returns test that absolute magnitude of difference
  #    is at least as great as that of the input z-transformed corr. diff.
  for (i in 1:M){
    permute <- cbind(v,rbinom(sum(n),1,0.5))
    rstar   <- c(cor(permute[permute[,3]==0,c(1,2)],method = method)[2,1],
                 cor(permute[permute[,3]==1,c(1,2)],method = method)[2,1])
    zstar   <- atanh(rstar)
    rtest   <- c(rtest,
                 abs(zstar[1]-zstar[2]) > abs(z[1]-z[2]))
    } 
  
  # return p-value: proportion of test results at least as large as obs'd
  p <- mean(rtest)
  return(p)
}
\end{lstlisting}

\section{Simulation}
\subsection{Approach for one simulation}
A function \code{corr\_diff\_test()} was developed to undertake a single comparative simulation using any of the above tests (listing \ref{lst:corr_diff}). Within a single simulation, each requested test is evaluated using samples drawn from the same two simulated bivariate populations (MZ and DZ), returning a $p$-value.  The analytic Fisher Z test returns either a $p$-value or a power estimate based on the population parameters.  
\\
\\
In the detailing of computational aspects of our methodology we use the term 'parameter' to refer to one of the options which may be specified within a function; an argument is the specific value which is passed to that parameter. For example, the parameter $\rho$ for the respective MZ and DZ groups may be defined by specifying the argument \code{rho = c(-0.65,0.2)}. The main parameters which can be specified in the function call to \code{corr\_diff\_test()} are described with example arguments in Table \ref{table:corr_params}.  In the following text we refer to the set of parameters that give rise to a simulation of estimated power for a particular test as a scenario.  Power estimates returned across a series of tests for comparison purposes are refered to as a composite scenario.

\begin{lstlisting}[float=h,caption={Single run simulation code},label={lst:corr_diff}]
corr_diff_test <- function(rho = c(.2,.5), n = c(30,90), distr = "normal",
                    param1a = c(0,0), param1b = c(0,0),param2a = c(1,1), param2b = c(1,1),
                    alpha = 0.05, sidedness = 2, test = c("fz","gtv","pt","slr","zou"),
                    method ="pearson", lower.tri = FALSE) {
  if(lower.tri==TRUE){
    # optionally, only calculate results for lower matrix half 
    #   when comparing across all correlation combinations
    if(rho[1] < rho[2]) { 
      return(NA)
    }
  }
  # initialise empty results vector
  results <- list()
  
  # if requested, process analytical Fisher's Z
  if ("fz_nosim" %in% test) {
    results[["fz_nosim"]] <- fz_ns_compiled(rho[1],rho[2],n[1],n[2], 
                                      alpha = 0.05, sidedness = 2, method = method, power = FALSE)
    if(length(test)==1) return(results)
  }
  # process selected hypothesis tests, each using same draw of simulated data
  require("simstudy")
  a <- genCorGen(n[1], nvars = 2, params1 = param1a, params2 = param2a,  
                dist = distr, corMatrix = matrix(c(1, rho[1], rho[1], 1), ncol = 2), 
                wide = TRUE)[,2:3]
  b <- genCorGen(n[2], nvars = 2, params1 = param1b, params2 = param2b,  
                dist = distr, corMatrix = matrix(c(1, rho[2], rho[2], 1), ncol = 2), 
                wide = TRUE)[,2:3]
  if ("fz"       %in% test) results[["fz"]]       <- fz_compiled(a,b)
  if ("gtv"      %in% test) results[["gtv"]]      <- gtv(a,b) # uses rccp ; so elsewise compiled
  if ("gtvr"     %in% test) results[["gtvr"]]      <- gtv_compiled(a,b) 
  if ("pt"       %in% test) results[["pt"]]       <- pt_compiled(a,b)
  if ("slr"      %in% test) results[["slr"]]      <- slr_compiled(a,b)
  if ("zou"      %in% test) results[["zou"]]      <- zou_compiled(a,b)[1]
  return(rbind(results[test]))
}
\end{lstlisting}

The function \code{corr\_diff\_test()} uses the $R$ package \code{simstudy} function \code{genCorGen()} to generate bivariate correlated data for the simulated MZ (group \code{a} in the code above) and DZ (group \code{b}) twin pair samples \cite{simstudy2018}.  The choice of available distributions and parameterisations is normal($\mu,\sigma$), binomial(probability $p$), Poisson(rate $\lambda$) gamma($\mu,\text{dispersion} \ k$), or uniform(min, max).  In addition to specifying sample size, distribution and parameterisation, a correlation matrix may be specified; this was used to parameterise the underlying population correlations from which bivariate samples should be drawn.  Three distinct distribution types were modelled in our simulation based power analysis: normal, 'mild' skew and 'extreme' skew. These are respectively explained in the captions of Figures \ref{fig:dist_norm}, \ref{fig:dist_gamma1}, and \ref{fig:dist_gamma2}, which illustrate example sample draws from these distributions.  

\begin{figure}[htbp]
\sidecaption[t]
%\centering
\fbox{\includegraphics[scale=0.52]{{../figs/distx_normal_60_120}.pdf}}
%\picplace{5cm}{2cm} % Give the correct figure height and width in cm
\caption{An example of the bivariate normal scenario, with distributional assumptions asymptotically met.  Both variables are standardised with mean $\mu=0$ and standard deviation $\sigma=1$.}
 % and distribution $\sim N\bigg{\boldsymbol\mu = \begin{pmatrix} 0 \\ 0 \end{pmatrix}, \quad \boldsymbol\Sigma = \begin{pmatrix} 1 & \rho \\ \rho  & 1 \end{pmatrix} \bigg)$.
% \caption{An example of the bivariate normal scenario, under which our distributional assumptions are asymptotically met.  This was specified with both variables standardised having mean $\mu=0$ and standard deviation $\sigma=1$ and distribution $\sim N\bigg{\boldsymbol\mu = \begin{pmatrix} 0 \\ 0 \end{pmatrix}, \quad \boldsymbol\Sigma = \begin{pmatrix} 1 & \rho \\ \rho  & 1 \end{pmatrix} \bigg)$.}
\label{fig:dist_norm}       % Give a unique label
\end{figure}

\begin{figure}[htbp]
\sidecaption[t]
%\centering
\fbox{\includegraphics[scale=0.52]{{../figs/distx_gamma_mildskew_60_120}.pdf}}
%\picplace{5cm}{2cm} % Give the correct figure height and width in cm
\caption{A 'mild skew' scenario based on a gamma distribution with mean 1.5 and dispersion 0.09 (which the genCorGen function uses to inform shape and scale parameters for the distribution).  This parameterisation was chosen through experimentation with the intent to represent a mild departure from an assumed normal population distribution, with a slight positive skew}
\label{fig:dist_gamma1}       % Give a unique label
\end{figure}

\begin{figure}[htbp]
\sidecaption[t]
%\centering
\fbox{\includegraphics[scale=0.52]{{../figs/distx_gamma_extrskew_60_120}.pdf}}
%\picplace{5cm}{2cm} % Give the correct figure height and width in cm
\caption{An 'extreme skew' scenario based on a gamma distribution with mean 1 and dispersion 5.  This results in an extreme positive skew to the distribution, analogous to that of biological processes where most observations will be clustered around a certain value, however some outliers may be extremely elevated.}
\label{fig:dist_gamma2}% Give a unique label
\end{figure}


\begin{table}\centering
\caption{Description of parameter options for single simulation \label{table:corr_params}}
\begin{tabular}{cll}
  \toprule
  \textbf{Parameter} & \textbf{Description} & \textbf{Example arguments} \\ [0.5ex] 
  \midrule
  \code{method}    & Correlation method to use for testing difference                  & \code{'pearson'}                 \\
  \code{rho}       & $\rho$ for each group's bivariate distribution                    & \code{c(-0.21,0.59)}             \\
  \code{n}         & Sample size for groups 1 (MZ) and  2 (DZ)                         & \code{c(30,60)}                  \\
  \code{dist}      & Distribution to be used for both groups' bivariate distribution \ & \code{'normal'}                  \\
  \code{param1a}   & Distribution parameter 1 for respective samples in group 1        & \code{c(0,0)}                    \\
  \code{param1b}   & Distribution parameter 1 for respective samples in group 2        & \code{c(0,0)}                    \\
  \code{param2a}   & Distribution parameter 2 for respective samples in group 1        & \code{c(1,1)}                    \\
  \code{param2b}   & Distribution parameter 2 for respective samples in group 2        & \code{c(1,1)}                    \\
  \code{test}      & Tests to be evaluated                                             & \code{c("fz\_nosim","fz","gtv")} \\
  \code{alpha}     & $\alpha$ value to use for hypothesis tests                        & \code{0.05}                      \\
  \code{sidedness} & Sidedness for hypothesis tests                                    & \code{2}                         \\
  \bottomrule 
\end{tabular}
\end{table}

\subsection{Approach for multiple simulations}
The \code{corr\_diff\_test()} function described above runs a single simulation of drawing from samples from two bivariate populations.  However, for asymptotic normality to hold --- the long run approximation of a normal distribution due to the Central Limit Theorem \cite{Casella2002} --- many more simulations must be run to achieve a fair assessment of the proportion of null hypotheses rejected when false for a particular scenario.
\\
\\
A wrapper function \code{corr\_power()} allows for the \code{corr\_diff\_test()} function to be called $M$ times, returning a power estimate for each test specified in the function call.  These power estimates are derived from the series of simulated $p$-values for each test considered, or directly in the case of the analytic Fisher's Z test.

\section{Scenario combinations}
The flexibility of the simulation commands we developed allows for an very broad array of scenarios to be considered.  A researcher could use these tools as is to aid in the development of a statistical analysis plan for their study.  For this report we had to decide on a limited subset of scenarios for consideration.  Two important considerations guiding this decision were the minimum number of scenario combinations required to facilitate useful comparisons of scenarios, and the time taken to run each of these.  Our initial plan for the series of scenarios is reported in table \ref{table:combos}.
\\

\begin{table}\centering
\caption{Description of parameter options for single simulation \label{table:combos}}
\begin{tabular}{llr}
  \toprule
  \textbf{Parameter} & \multicolumn{2}{c}{\textbf{Initial plan}} \\ 
  \cmidrule(lr){2-3} 
   & \textbf{Argument resolution} & \textbf{Combinations}	\\
  \midrule
  \code{method}    & Pearson and Spearman correlations                                 & 2 \\
  \code{rho}       & $\rho$ combinations\: -0.95 through 0.95 at 0.5 resolution         & $39^2 = 1521$ \\
  \code{n}         & group combinations\: 15, 30, 60, 120, 240, 480, 960                      & $7^2 = 49$ \\
  \code{dist}      & normal, 'mild skew', 'extreme skew'                               &  3 \\
  \code{param1a}   & dictated by distribution choice, above                            & -  \\
  \code{param1b}   & dictated by distribution choice, above (equal to param1a)         & -  \\
  \code{param2a}   & dictated by distribution choice, above                            & -  \\
  \code{param2b}   & dictated by distribution choice, above (equal to param2a)         & -  \\
  \code{test}      & Fisher's Z (analytic and sim), Zou's CI, GVT, SLR, PT             & 6  \\
  \code{alpha}     & .05                                                               & 1  \\
  \code{sidedness} & 2                                                                 & 1  \\
  \midrule
  Total scenarios &                                                            & 2,683,044  \\
  Total simulations & 1,000 simulations for each scenario                   & 2,683,044,000 \\
  Total simulations & 100, 1,000 and 10,000 simulations for each scenario (unrealistic!) &  29,781,788,400 \\
  \bottomrule 
\end{tabular}
\end{table}

\\
We decided \textit{a prior} to set some parameters as fixed, : we only conducted two-sided tests with $\alpha$ of 0.05;  having decided to limit ourselves to three basic distributional forms (normal, and two kinds of non-normal using distinct gamma distribution parameterisations) the distribution parameters were fixed to achieve these forms; the respective simulations of MZ and DZ twin pair samples each use the same distributional form, although the population correlation and sample size may vary (e.g. we don't compare bivariate normal MZ with a gamma skewed DZ); the simulated bivariate data for each twin group shares the same parameterisation (e.g. for normal data both MZ or DZ variables simulated based on $\mu$ 0 and $\sigma$ 1).  Nevertheless, we were aware that our initial plan would be over-ambitious: were each scenario to be processed consecutively, each taking 1 second to process at an optimistically steady rate with no computer crashes we might expect 1,000 simulations of each scenario in Table \ref{table:combos} to take $2,683,044,000/60/60/24/365 \approx 85$ years!  Under advice from my colleague Koen Simons, I undertook time tests of 1,000 iterations of each function and their byte code compiled versions, employing only the most efficient versions.  The permutation test implementation was particularly inefficient, and given time constraints for improving the code's efficiency this was abandoned.  Noting that the resolution of correlation combinations was a major contributor to anticipated length of processing time, this was reduced to comparison of correlations from -0.9 through 0.9 at a 0.1 resolution resulting in 361 instead of 1,521 correlation combinations.  Based on the preliminary time tests, the initial and revised time estimates are displayed along with function time results in Table \ref{table:times}.  These estimates suggested an anticipated running time of 16 days, based on my personal two core i7-processor laptop with 8gb RAM.
\\

\begin{table}\centering
\caption{Description of parameter options for single simulation \label{table:times}}
\begin{tabular}{lrr}
  \toprule
  \textbf{Test} &	\multicolumn{2}{c}{\textbf{Time/1000 runs (secs)}} \\
  \cmidrule(lr){2-3} 
   & \textbf{as is} & \textbf{compiled}				\\
  \midrule										
  Fisher's z (no sim) &         0.03 &    0.02 \\
  Fisher's Z          &         0.56 &    0.36 \\
  GTV (r)             &        18.65 &   16.55 \\
  GTV (R C++)         &              &   12.08 \\
  Permutation (PT)    &      2473.18 & 2341.62 \\
  SLR                 &         0.49 &    0.33 \\
  Zou's CI            &         0.38 &    0.28 \\
  \midrule
  \multicolumn{1}{l}{Total 1 (PT, R-compiled GTV)}       &	2493.29 & 2359.16  \\
  \multicolumn{1}{l}{Total 2 (No PT, RCCP-compiled GTV)} &	       	& 13.07    \\
  \multicolumn{1}{l}{Total 3 (No PT, R-compiled GTV)}    & 	20.11	  & 17.54    \\
  \multicolumn{1}{l}{Initial scenario: Total 1 $\times 1521 \times 49 \times 3 \times 2/60/60/24/365$}  & 35 years  & 33 years \\
  \multicolumn{1}{l}{Best scenario: Total 2 $\times 361 \times 49\times 3 \times 2 /60/60/24$}  & 25 days  & 16 days \\
  \multicolumn{1}{l}{Next best scenario: Total 3 $\times 361 \times 49\times 3 \times 2 /60/60/24$}  &    & 21 days \\
\bottomrule 
\end{tabular}
\end{table}
\\
The processing workflow used the R package data.table, a reported fast and memory efficient object for reading, writing and otherwise processing results \ref{r_dt}.  The data.table was set up in wide format with rows per composite scenario (106,134 rows) and columns per parameter with five additional columns to contain power estimates per test (13 columns, once processed).  In long form, this corresponds to 5 \times 106,134 = 530,670 power estimate scenario rows.  Each wide-form row corresponds to a call to the \code{corr\_power()} function. Results as reported in this report were calculated row-wise using the \code{data.table} objects optimised processing syntax.  A subsequent revision to the approach was made based on this experience, and this recommended approach will be noted in the discussion.
\\
\\
The full set of composite scenarios were processed using 100 simulations, and select scenarios using 1,000 simulations and 10,000 simulations.  
\begin{itemize}
\item Scenario subset 1: How does sample size impact power estimates?  
  \begin{itemize}
    \item Approach:
    \begin{itemize}
      \item hold constant \code{(rho1==0.2)&(rho2==0.5)}
      \item process and report results for 100, 1000 and 10,000 simulations
    \end{itemize}
    \item Considerations:
      \item number of simulations (validity)
      \item use of test
      \item use of Pearson or Spearman's correlation
      \item use of Distribution 
    \end{itemize}
  \end{itemize}
\item Scenario subset 2: How does MZ:DZ ratio impact power estimates?  
  \begin{itemize}
    \item Approach:
    \begin{itemize}
      \item hold constant \code{n1 == 60 and n2 == 120}; ie. n = 180, MZ:DZ ratio 0.5:1
      \item hold constant \code{n1 == 90 and n2 == 90}; ie. n = 180, MZ:DZ ratio 1:1
      \item process and report results for 1000 simulations
    \end{itemize}
    \item Considerations:
      \item use of test
      \item use of Pearson or Spearman's correlation
      \item use of Distribution 
      \item magnitude and difference of correlations
    \end{itemize}
  \end{itemize}
\end{itemize}
# Scenario A1
#  
# nrow(dtk[(n1==60)&(n2==120),)
# 2166 rows


The 100 simulation set of results was used as initial proof of concept for the approach; the scenarios using 1,000 results provide the main results for the inferences made in this report; the 10,000 simulations scenarios were produced in order to evaluate sensitivity of simulated power estimates to the number of simulation runs, and in particular establish validity of the choice of 1,000 simulations for main results.

\section{Evaluating power}

Using results of scenarios based on 10,000 simulations each, power estimates for detection of a difference in correlations from MZ twins with $\rho$ 0.2 and DZ twins with $\rho$ of 0.5 across a range of sample sizes and MZ:DZ ratios of .5:1 and 1:1 were compared using each of 5 tests, across the three distributions and measured with Pearson and Spearman correlations.  

To evaluate the validity of using 1,000 instead of 10,000 simulations to estimate power, results from the same set of parameters giving rise to the above scenarios were considered in graphic form comparing each of 100, 1000 and 10,000 simulations.  Holding all parameters except for sample size constant, a monotonic spline function based on power and $\log(n)$ is used to interpolate the power by sample size for each test. This in turn is used to estimate for each test the required sample size to achieve 80\% power for these 6 composite scenarios (3 distributions, two MZ:DZ sample size combinations).

Impact of magnitude of correlations on power to detect a difference in correlations is evaluated using fitted contour plots for each test, again by the three distribution types and two MZ:DZ ratios using sample size of 180, each evaluated using 1,000 simulations.  These 6 plots, evaluated across all correlation combinations for each test, are based on $ 6 \times 5 \times 361 = 10,830$ scenarios.

The same six composite scenarios as the power plots are used to evaluate 


 etc. I have put more old style contour plots in appendix,
which may be referred to — specific examples for GTV and SLR


results in format of images
\\
\\
contour plot
\\
\\  
interpolation using monotonic increasing spline function
\\
\\
Required sample size to achieve 80% power
\\
\\  
Difference to achieve 80% power
