\chapter*{1. Introduction}
\markboth{1. Introduction}{}
\setcounter{chapter}{1}
\addcontentsline{toc}{chapter}{1. Introduction}

			% o	Summary of background and research methods; why this analysis/ evaluation is important; how and why the data was collected (initial study aims, collection methods, response rates); specifics of data (number, variables, outcomes)
			% Research question, aim, objectives of study
			
			% Research question:
			% What are the existing methods for estimating power to detect a difference in correlations between identical (monozygotic) and non-identical (dizygotic) twins, how do these compare and can they be improved upon? 

\large


% \begin{figure}[htbp]
% \sidecaption[t]
% %\centering
% \fbox{\includegraphics[scale=0.5]{figures/PapuaEndemicity.png}}
% %\picplace{5cm}{2cm} % Give the correct figure height and width in cm
% \caption{caption for figure.}
% \label{fig:pvpr}       % Give a unique label
% \end{figure}
\tdn{Note: This, along with much else, is not written or structured in the way I intend to submit it.  Things are a sketch at the moment, and will be filled in from methods/results outwards.  The images in results section represent the main results, and the key comparisons provoking discussion}
\section{Background}
%% Intro

The classic twin study exploits the differing degrees of genetic relatedness in identical (\mz) and non-identical (\dz) twins in order to draw inferences on the heritability of traits.  In broad terms, heritability is the degree to which variation in a trait or phenotype, such as propensity to gain body weight, or become a centenarian, can be attributed to shared genetic effects.  The calculation and comparison of Pearson correlations across the two twin groups is a routine preliminary step undertaken by researchers in this field.  However, a range of factors can impact on researchers' ability to detect a true effect given data.  
This thesis reports on a simulation-based power analysis for the detection of differences in correlations between \mz and \dz twin pairs under a range of scenarios, and the associated development of R functions and an applied interactive power calculator.  These tools address an identified absence of tools for this fundamental step in the twin study context.
 
In this chapter we will first define key genetic concepts, how these are exploited by the classic twin study, and some of the assumptions which are relied upon in order to make such inferences.  Then, the concept of power analysis and related statistical concepts will be defined in order to provide background, justification and notation for the following chapters. 
 
\subsection{Twins and the classic twin study}
Identical twins (\mz, MZ) arise from the same zygote, or fertilised egg, and are genetically very similar.  Non-identical twins (\dz, DZ) arise from fertilisation of two seperate eggs, and are as genetically alike as ordinary siblings. The classic twin study is used to estimate the proportion of variation in traits which may be attributable to genetics, or heritability.  Estimates of heritability are conditional on key assumptions. 

The comparison of phenotypic traits within identical and non-identical twin pair samples allows for partitioning the variance in traits into that attributable to  shared environment, individual environment or to genetics.  This allows us to better understand the mechanics of health and disease processes so that we can develop intervention measures which appropriately target the hypothesised causal mechanisms.

Contemporary twin studies use mixed effects and structural equation modelling to evaluate differences in variance components for a particular trait between mono and dizygotic twins accounting for differential within pair similarities related to zygosity.  A recent article reported on the development of R commands which can be used to estimate the power to detect a difference in correlations using such models.  

However, a routine preliminary step undertaken by researchers in this field is the calculation and comparison of Pearson correlations across the two twin groups.  This research project focuses on the reported needs of researchers undertaking this early analysis step.

In undertaking a twin study we make certain assumptions, understanding that these likely do not strictly hold in practice, but the key one for the purposes of this power analysis is that our data is approximately normally distributed.

\subsection{Historical background}

The statistical treatment of correlation was popularised by Francis Galton.  In context of broad social interest in eugenics, Galton described methods which could be used to describe the 'co-relatededness' of variables sourced from closely related family members \cite{Galton1888,Galton1890}.  

Karl Pearson was a keen follower of Galton's research, and writing in the context of inheritance and natural selection made use of 'Galton's function', describing it as a coefficient of correlation \cite{Pearson1895}.  

Ronald Fisher observed that a geometric transformation of the correlation cofficient using its inverse hyperbolic tangent could be used to approximate a normal distribution \cite{Fisher1915}.  This has the effect of mapping the distribution of correlation of coefficients from a domain of negative 1 through positive one to negative infinity through positive infinity. Being a simple and accurate approximation of the normal distribution, this transformation known as Fisher's Z is ubiquitous in statistical treatment of correlation coefficients, for example when seeking to compare their differences.

Florence Nightingale David was a protege of Pearson's who suggested that she prepare a volume of numerically accurate tables and interpolated plots of the distribution of the sample correlation coefficient r given n and the population correlation rho which could act as a standard against which to judge approximations such as that of Fisher \cite{David1938}. 
%  This visualisation of David's of the chance of rejecting the null hypothesis when true given alpha and rho and n was an influence on this project's presentation of results.

In the context of genetics and kinship, Douglas Falconer outlined methods of using comparison of identical and non-identical twins for estimating heritability, and noted some of the assumptions that this involves \cite{Falconer1960}.

Michael Neale and colleagues developed methods and software to facilitate the analysis of variance components in twin studies using structural equation modelling \cite{Neale1992}.  Brad Verhulst, building on the work of Peter Visscher, developed functions for power analyses in this variance component modelling context, for example detecting a difference in genetic correlations \cite{Visscher2004,Visscher2008a}.

This project is concerned with power to detect a difference in Pearson correlations as part of preliminary analysis before variance component modelling.

Bivariate distribution
$$\boldsymbol\mu = \begin{pmatrix} \mu_X \\ \mu_Y \end{pmatrix}, \quad \boldsymbol\Sigma = \begin{pmatrix} \sigma_X^2 & \rho \sigma_X \sigma_Y \\ \rho \sigma_X \sigma_Y  & \sigma_Y^2 \end{pmatrix}$$
Assuming our variables are scaled to have mean of zero and standard deviation 1, the notation is simplified as
$$\boldsymbol\mu = \begin{pmatrix} 0 \\ 0 \end{pmatrix}, \quad \boldsymbol\Sigma = \begin{pmatrix} 1 & \rho \\ \rho  & 1 \end{pmatrix}$$
                             
$$\rho_{X,Y} = \frac{\Cov(x,y)}{\sigma_x \sigma_y} = \frac{\operatorname{E}[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X\sigma_Y}$$
and is estimated by the sample correlation coefficient $r$
$$r_{x,y} = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2 \sum_{i=1}^{n} (y_i - \bar{y})^2}}$$

$$z = \arctanh(r) = \frac{1}{2} \log_e \frac{1+r}{1-r}$$


\begin{figure}[htbp]
\sidecaption[t]
%\centering
\fbox{\includegraphics[scale=1.3]{../figs/r_to_z.pdf}}
%\picplace{5cm}{2cm} % Give the correct figure height and width in cm
\caption{Transformation of $r$ to $z$ using Fisher's method.}
\label{fig:ztransform}       % Give a unique label
\end{figure}


\section{Power analysis and hypothesis testing} 
Power analysis involves a compromise between type 1 ($\alpha$) and type 2 ($\beta$) error thresholds, respectively representing the expected proportion of null hypotheses to be rejected when true and not rejected when false  \cite{Freiman1978}.  These could be chosen to suit the requirements of a particular study, but for historical reasons the respective values chosen tend to be 5\% ($\alpha = .05$) and 20\% ($\beta = 0.2$)} \cite{Cohen1988}.  
\subsection{Significance testing and controversy}
There are controversies around the choice of such values, relating to what it means to deem something as 'statistically significant', a synonym for $p < \alpha$. A recent commentary suggested 'redefining' significance as $p < 0.005$ \cite{Benjamin2018}; other authors in a biostatistics context have advised that reporting of exact p-values is in general preferable to dichotomisation at a somewhat arbitrary $\alpha$ level, and that there is justification for use in some contexts of confidence intervals based on $\alpha=0.1$ \cite{Clayton1993}.  These are epistemological questions, detailed discussion of which is beyond the scope of this research project.  However it is important to acknowledge that the present study is concerned with an applied statistical question (power to detect differences in correlations in groups with distinct genetic relatedness) with strong historical links to the hypothesis testing paradigm.  
\subsection{Importance of power analysis}
Regardless of debates surrounding the use of hypothesis testing and thresholding, the question of power is one of academic rigour with moral implications: if a study is to be conducted with support through significant contribution of public resources in the way of grant funding, there is an ethical imperative to consider $a \ priori$ whether the experiment in question can anticipate production of meaningful evidence \cite{Freiman1978,Cohen1988}.  Power analysis aims to answer this question through consideration of the sample size required to detect an effect of such magnitude to be considered meaningful given the specified values of $\alpha$.  
\subsection{Calculation of power}
The probability of observing a true effect, the power of a statistical test, is equal to the proportion of null hypotheses rejected when false; that is, $1 - \beta$ \cite{Cohen1988}.  Hence, the choice of $\beta$ will indicate directly the intent for power: if in planning a twin study we agree an appropriate value for $\beta$ is 0.2, then we are saying that our power to detect a difference of the required magnitude between identical and non-identical twins should be at least as high as 0.8, or 80\%. The ability to achieve this power depends on sample size, the ratio of MZ to DZ twins, the magnitude of the respective correlations themselves, and the degree to which our assumptions of bivariate normality hold. The robustness of the choice of test method employed to departures from distributional assumptions is also an important consideration.

\section{DETRITUS}
\tdn{sort this out!}
The ratio of MZ to DZ twins is an important parameter to consider with regard to power to estimate variance components in twin studies, involving a trade off between power to detect additive genetic ($>1:1$) or shared environmental effects ($<1:1$) \cite{Visscher2008}.  Such effects may be the main objects of interest in contemporary studies when planning a study, and power calculators such as that of Verhulst \cite{Verhulst2017} specifically cater to these concerns.  However


Through a review of the literature relating to twins, correlations, power and simulations was undertaken to inform our approach.  Results of a search for abstracts relating to power analyses concerned with all these themes from a series of structured searches were limited.  Tracing back references cited in the article which inspired this research project \cite{Verhulst2017}, a number of key historical texts were identified and informed the preceding method section: \cite{David1938} on correlation and hypothesis tests, \cite{Falconer1960} on heredity and correlation,  \cite{Cohen1988} on power for differences in correlation, 

We identified a series of suitable approaches and tests for evaluating differences in Pearson and Spearman correlations in groups.  The Spearman correlation is a non-parametric alternative to Pearson's, using the same formula on the rank ordered variables rather than their raw values.


Fisher's Z transformation, the inverse hyperbolic tangent, maps the correlation coefficient from a domain of -1 through 1 to negative infinity through positive infinity, with approximate normal distribution.  This classic formulation is still used in functions found in statistical packages such as $R$ and Stata \cite{R2018,StataCorp2013}.

David compared the use of the z-transformation and other methods such as the Lagrangian four-point formula for use in hypothesis tests concerning $r$, concluding that the z-transformation should be appropriate for most purposes since little difference was observed between the two methods' results given sample sizes greater than 25 \cite{David1938}.
