\chapter*{4. Discussion}
\markboth{Discussion}{}
\setcounter{chapter}{4}
\setcounter{section}{0}
\addcontentsline{toc}{chapter}{4. Discussion}
% put in comments for each paragraph to remind yourself to stay on topic!!

% \cite{Price2007,Rahimi2014,Naing2014}

\section{section title}
\tdn{for now, this is plonked from presentation.  I will discuss implications of results and relate to Visscher article, as well as those few results included in appendix - Twin Studies using Pearson correlations (some of whom's power seemed to post hoc check out; others were clearly underpowered).  I know this is really the most important part.  I'll get it in shape.}

\tdn{Efficiency (PT test); Number of simulations; ratio; problem with formula approach with assumption violation; problem with bias in methods (SLR); Strengths; Limitations; Next}

Despite the reduced parameter set, our results are comprised of more than half a million power estimates which can be accessed to answer specific questions.
\\
While the main use of such results are for considering particular scenarios, we can average over these for marginal estimates; under approximate normality the SLR test was estimated to have 82% power on average, while the other tests had approximately 75%.  This result which is reflected in this plot here for example, with the higher power estimate from SLR estimate suggesting a smaller required sample size, is surprising.
\\
The fitted contour plot on the left here compares power to detect a difference using all correlation combinations given groups sizes, in this example, under a bivariate normal distribution.  The blue line indicates the 80% power threshold.
\\
On the right sample size estimates to achieve 80% power given population correlation coefficients of 0.2 and 0.5 are compared across the 5 implemented tests.  Stata produces two correlation power estimates with plots like these using the Fisher Z formula.  We often assume that our tests are robust to departures from normality, but it is interesting to ask how would this perform if normality assumption were severely violated?
\\
We can see here the extreme under estimation in sample size required to achieve 80% power given an extreme positively skewed bivariate distribution when using the formula based approach compared with the simulation-based tests. 
\\
The SLR test appears a strong performer here - but its systematic elevation at tails of distribution is concerning -- does this reflect a systematic bias, and perhaps innacurate rather than truly improved performance?  
\\
When no difference in correlations is present under bivariate normal distribution we would expect power equivalent to our alpha level of 0.05, which, approximately, the other tests have; however, the SLR test has approximately 20\%.  This suggests its estimates here are upwardly biased.
\\
After the SLR test the GTV was the next most powerful, but only marginally moreso than the Fisher's Z based tests.  


\\
We developed a flexible and extensible architecture geared to solving future problems.
\\

\tdn{discuss nested simulations - GVT and PT}

However, the programming and analysis took longer than anticipated.  The results I have shown today were processed using 100 simulations per parameter combination.  The 1000 simulation results should be completed to update my results in a day or so.
\\
There is more we can do to make this of more particular use in the twin context, for example by evaluating correlations in simulations using multivariable regression methods we could account for partial correlations; if we did this using mixed effects methods we could also consider power for difference in intra-class correlations.
\\
Improve efficiency to allow higher resolution estimation
\\

??
Cite Kaplen article on heritability meta-analysis --- could lead into this by discussing the question of relavence of finding average power overlooking the particularities
\\
Pre- and post-hoc analysis discussion; later and confidence intervals more use
\\
keep emphasis on assumptions, hence need to consider a variety of scenarios
\\

Difference plot is problematic \; an approach using the most pessimistic scenario (maximum required distance?) would arguably be more useful than average difference.  Nevertheless, visualising the underlying scatter plot of estimates was useful to evalute impact of changing parameters such as the MZ:DZ ratio on power give difference.


\section{Strengths}
, and there are several benefits of this approach

The use of this approach 
particular scenario were recorded to ensure accurate scenario retrieval and ability to interpolate power estimates based on a subset of scenarios.  


\section{Computational considerations}
It can be anticipated that simulation results based on 100 simulations would be unstable, however comparison with results produced using 1,000 and 10,000 simulations each allows for evaluation of sensitivity of power estimates to choice of simulation runs; in particular, to evaluate whether our goal of 1,000 simulations per scenario is sufficiently valid.  It was originally intended to run all scenarios at 1,000 simulations each, however following a fortnight of processing on an 8 core workstation once results finished it was realised that (despite test runs) a syntax error in specifying the vector of additional columns to be created to contain results meant only the analytical result (which didn't require simulation) was retained.

Explain why not: Marginal estimates for power of each test across the range of correlations considered will be given by distribution and application of Pearson or Spearman test method  --- should be applied, not marginal


% \begin{lstlisting}[language=SQL,float=h,caption={Example inspection of simulation results in database, while parallel processing is occurring.},label={lst:corrx_sql}]

% corrx_twins=# SELECT NOW() AS time, COUNT(*),106134 AS goal, ROUND(COUNT(*)/106134.0*100,1) AS percent  FROM corrx_100;
             % time              | count |  goal  | percent
% -------------------------------+-------+--------+---------
 % 2018-06-09 10:31:24.646759+10 | 32100 | 106134 |    30.2
% (1 row)

% corrx_twins=# SELECT * FROM corrx_100 LIMIT 10;
 % simx  |  method  |  dist  | p1 | p2 | n1 | n2 | rho1 | rho2 |  fz_nosim  |  fz  | gtvr | slr  | zou
% -------+----------+--------+----+----+----+----+------+------+------------+------+------+------+------
 % 53068 | spearman | normal |  0 |  1 | 15 | 15 | -0.9 | -0.9 |    0.03    | 0.05 | 0.05 | 0.08 | 0.05
     % 1 | pearson  | normal |  0 |  1 | 15 | 15 | -0.9 | -0.9 |    0.03    | 0.04 | 0.05 | 0.05 | 0.04
 % 53069 | spearman | normal |  0 |  1 | 15 | 15 | -0.9 | -0.8 |    0.15    | 0.08 | 0.09 | 0.14 | 0.07
     % 2 | pearson  | normal |  0 |  1 | 15 | 15 | -0.9 | -0.8 |    0.15    | 0.13 | 0.14 | 0.14 | 0.13
 % 53070 | spearman | normal |  0 |  1 | 15 | 15 | -0.9 | -0.7 |    0.32    | 0.34 | 0.35 | 0.39 | 0.34
     % 3 | pearson  | normal |  0 |  1 | 15 | 15 | -0.9 | -0.7 |    0.32    | 0.29 | 0.31 | 0.35 | 0.29
 % 53071 | spearman | normal |  0 |  1 | 15 | 15 | -0.9 | -0.6 |    0.48    | 0.55 | 0.57 | 0.63 | 0.55
     % 4 | pearson  | normal |  0 |  1 | 15 | 15 | -0.9 | -0.6 |    0.48    | 0.54 | 0.56 | 0.59 | 0.54
 % 53072 | spearman | normal |  0 |  1 | 15 | 15 | -0.9 | -0.5 |    0.62    | 0.63 | 0.63 | 0.66 | 0.63
     % 5 | pearson  | normal |  0 |  1 | 15 | 15 | -0.9 | -0.5 |    0.62    | 0.64 | 0.65 | 0.67 | 0.64
% (10 rows)

% corrx_twins=# SELECT NOW() AS time, COUNT(*),106134 AS goal, ROUND(COUNT(*)/106134.0*100,1) AS percent  FROM corrx_100;
             % time              | count |  goal  | percent
% -------------------------------+-------+--------+---------
 % 2018-06-09 16:28:25.912515+10 | 36377 | 106134 |    34.3
% (1 row)
% \end{lstlisting}

